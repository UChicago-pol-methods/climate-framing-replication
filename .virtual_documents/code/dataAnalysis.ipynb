


import numpy as np
from matplotlib import pyplot as plt
import pandas as pd
import seaborn as sns
import random
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
import statsmodels.api as sm
from statsmodels.iolib.summary2 import summary_col


# import data
data = pd.read_csv("./../data/ssi-data-cleaned.csv")


# Set up
treatments = {0: "No framing",
              1: "Negative science",
              2: "Religious",
              3: "Equity",
              4: "Efficiency",
              5: "Secular"}
data["treatment_frame"] = data["treatment_value"].map(treatments)
data_rep = data[data['party'] == 1]
data_dem = data[data['party'] == -1]
data_ind = data[data['party'] == 0]

set_seed = 42
num_folds = 5
covariates_pre = ['gastax', 'carbtax', 'treaty', 'regcarb']

outcome_var = 'post_test'
covariates = ['age', 'party_id', 'employment_status', 'race_white', 'income_level', 
              'relationship', 'college', 'sex_id', 'prosociality', 'gastax', 
              'carbtax', 'treaty', 'regcarb', 'ideology', 'scientific_confidence', 
              'reward_consequence', 'religiosity', 'rel_freq', 'economic_reasoning']
treatment_vars = [f"treatment_{i}" for i in range(1, 6)]
control_var = 'pre_test'


# Distribution of subjects across treatment conditions (like Table 1 from paper)
treatment_freq = data[["treatment_value", "treatment_frame"]].value_counts()
treatment_rel_freq = data["treatment_frame"].value_counts(normalize=True)
treatment_freq.to_frame().sort_index().join(treatment_rel_freq)





pd.pivot_table(data, values=['pre_test', 'post_test', ],
               index=['treatment_value','treatment_frame'],
               aggfunc=['mean'])





pd.pivot_table(data, values=["post_test", 'pre_test'],
               index=["party", "treatment_frame"], aggfunc=['mean'])








# with multiple treatments
def lin_estimator_mult_treat_formula(data, y_var, treatment_vars, covariates):
    """
    Inputs:
        data: pandas dataframe containing all x and y columns
        y_var: name of y variable
        treatment_vars: treatment dummy variables
        covariates: list of string names of covariate

    Returns: Lin estimator model, formula
    """
    # Demean the covariates
    df = data.copy()
    for cov in covariates:
        # ignore binary variables
        if (df[cov].max() == 1 and df[cov].max() == 0) :
            df[cov + '_demeaned'] = df[cov]
        else:
            df[cov + '_demeaned'] = df[cov].dropna() - df[cov].dropna().mean()

    # Define the regression formula
    # Include each treatment indicator
    treatments_formula = " + ".join(treatment_vars)

    # Include each interaction term (automatically includes individual covariates)
    interactions = []
    for treatment in treatment_vars:
        for cov in covariates:
            interactions.append(f"{cov+ '_demeaned'} * {treatment}")
    
    interactions_formula = " + ".join(interactions)

    # Full formula -- include any other control(s)
    formula = f"{y_var} ~ {treatments_formula} + {interactions_formula}"

    # Fit the regression model and save results object
    model = sm.OLS.from_formula(formula, data=df).fit()

    # Return results object with robust covariance type
    return model.get_robustcov_results(cov_type="HC3"), formula

# with one treatment
def lin_estimator_formula(data, y_var, treatment_var, covariates):
    """
    Inputs:
        data: pandas dataframe containing all x and y columns
        y_var: name of y variable
        treatment_var: single treatment variable 
        covariates: list of string names of covariate

    Returns: Lin estimator model, formula
    """
    df = data.copy()
    # Demean the covariates
    for cov in covariates:
        # ignore binary variables
        if (df[cov].max() == 1 and df[cov].max() == 0) :
            df[cov + '_demeaned'] = df[cov]
        else:
            df[cov + '_demeaned'] = df[cov].dropna() - df[cov].dropna().mean()

    # Define the regression formula

    # Include each interaction term (automatically includes individual covariates)
    interactions = []
    for cov in covariates:
        interactions.append(f"{cov+ '_demeaned'} + {cov+ '_demeaned'} * {treatment_var}")
    
    interactions_formula = " + ".join(interactions)

    # Full formula -- include any other control(s)
    formula = f"{y_var} ~ {treatment_var} + {interactions_formula}"

    # Fit the regression model and save results object
    model = sm.OLS.from_formula(formula, data=df).fit()

    # Return results object with robust covariance type
    return model.get_robustcov_results(cov_type="HC3"), formula





# Function to extract treatment effects from model
def extract_treatment_effects(model, treatment_vars):
    coefs = dict(zip(model.model.exog_names, model.params))
    effects = {var: coefs.get(var, 0) if coefs.get(var) is not None else 0 for var in treatment_vars}
    return effects

# Function to find the best treatment
def find_best_treatment(effects):
    if effects:
        return max(effects, key=effects.get)
    return None

# Function to assign the best treatment indicator
def assign_best_treatment_indicator(test_data, best_treatment):
    if best_treatment:
        test_data['best_treatment_indicator'] = (test_data[best_treatment] == 1).astype(int)
        test_data['not_best_treatment_indicator'] = ((test_data[best_treatment] != 1) * (test_data['treatment_value']!=0) ).astype(int)
    else:
        data['best_treatment_indicator'] = 0

# Train models and predict outcomes
def train_and_predict(train_data, test_data, features, random_state):
    predictions = {}

    # Train a model for each treatment condition and predict for the test data
    for treatment in treatment_vars:
        # Assuming binary treatment, filter data where treatment is active
        treated_data = train_data[train_data[treatment] == 1]
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(treated_data[features], treated_data[outcome_var])
        # Store predictions for each treatment
        predictions[treatment] = rf.predict(test_data[features])

    return predictions

# Function to check if the treatment equals 1
def check_treatment(row, column):
    treatment_col = row[column]
    return int(row[treatment_col] == 1)

# Function to assing the best personalized treatment indicator
def assign_best_personalized_treatment_indicator(test_data, results):
    # Create a DataFrame from the results with appropriate indexing
    results_df = pd.DataFrame(results, index=test_data.index)
    # Use np.argmax on axis=1 to find the indices of maximum values along the horizontal axis
    best_treatment_indices = np.argmax(results_df.values, axis=1)
    # Convert indices to a Series to use the map function
    best_treatment_series = pd.Series(best_treatment_indices, index=test_data.index)
    # Map indices to treatment variable names
    best_treatment = best_treatment_series.map(dict(enumerate(treatment_vars)))
    test_data['best_personalized_treatment'] = best_treatment
    # Apply the function across the DataFrame rows
    test_data['best_personalized_treatment_indicator'] = test_data.apply(check_treatment, column = 'best_personalized_treatment', axis=1)
    test_data['not_best_personalized_treatment_indicator'] = ((test_data['best_personalized_treatment_indicator'] != 1) * (test_data['treatment_value']!=0) ).astype(int)






# Simple difference in means estimator
treatments_formula = " + ".join(treatment_vars)
formula = f"post_test ~ {treatments_formula}"

# Fit the regression model and save results object
model = sm.OLS.from_formula(formula, data=data).fit()

model0_results = model.get_robustcov_results(cov_type="HC3")
model0_results.summary()


# Fit the regression model and save results object
model_rep = sm.OLS.from_formula(formula, data=data_rep).fit()
model_dem = sm.OLS.from_formula(formula, data=data_dem).fit()
model_ind = sm.OLS.from_formula(formula, data=data_ind).fit()

model0_results_rep = model_rep.get_robustcov_results(cov_type="HC3")
model0_results_dem = model_dem.get_robustcov_results(cov_type="HC3")
model0_results_ind = model_ind.get_robustcov_results(cov_type="HC3")

print (summary_col([model0_results_rep, model0_results_dem, model0_results_ind],stars=True,float_format='%0.3f',
                  model_names=['Difference-in-means\nRep\n(1)','Difference-in-means\nDem\n(2)','Difference-in-means\nInd\n(3)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept'] + [f"treatment_{i}" for i in range(1, 6)],
                  drop_omitted=True))


# Lin estimator
model1_results, model1_formula = lin_estimator_mult_treat_formula(data,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates)

model1_pre_results, model1_formula = lin_estimator_mult_treat_formula(data,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)


model1_pre_results_dem = lin_estimator_mult_treat_formula(data_dem,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]

model1_pre_results_rep = lin_estimator_mult_treat_formula(data_rep,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]

model1_pre_results_ind = lin_estimator_mult_treat_formula(data_ind,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]
# model1_results.summary()


print (summary_col([model0_results, model1_results, model1_pre_results],stars=True,float_format='%0.3f',
                  model_names=['Difference-in-means\n(1)','Lin (all covariates)\n(2)','Lin (pre-test only)\n(3)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept'] + [f"treatment_{i}" for i in range(1, 6)],
                  drop_omitted=True))





print (summary_col([model1_pre_results_rep, model1_pre_results_dem, model1_pre_results_ind],stars=True,float_format='%0.3f',
                  model_names=['Lin (pre-test only)\nRep\n(1)','Lin (pre-test only)\nDem\n(2)','Lin (pre-test only)\nInd\n(3)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept'] + [f"treatment_{i}" for i in range(1, 6)],
                  drop_omitted=True))





# Shuffle data and split into folds
shuffled = data.sample(frac=1, random_state=set_seed)
folds = np.array_split(shuffled, num_folds)

# Initialize storage for results and effects
combined_data = data.iloc[:0,:].copy()
all_effects = []
best_treatments = []

# Iterate over each fold, using it as the test set, and the others as the training set
for i in range(num_folds):
    test_fold = folds[i]
    training_folds = pd.concat([folds[j] for j in range(num_folds) if j != i])
    
    # Train model on the combined training folds
    training_model = lin_estimator_mult_treat_formula(training_folds, outcome_var, treatment_vars, covariates_pre)[0]
    training_effects = extract_treatment_effects(training_model, treatment_vars)
    
    # Find the best treatment from the training model
    best_treatment = find_best_treatment(training_effects)
    assign_best_treatment_indicator(test_fold, best_treatment)

    all_effects = all_effects + [training_effects]
    best_treatments = best_treatments + [best_treatment]
    combined_data = pd.concat([combined_data, test_fold])

# Simple difference in means estimator
treatments_formula = " + ".join(['best_treatment_indicator', 
                                                   'not_best_treatment_indicator'])
formula = f"post_test ~ {treatments_formula}"

# Fit the regression model and save results object
model = sm.OLS.from_formula(formula, data=combined_data).fit()

model3_results = model.get_robustcov_results(cov_type="HC3")

model3_pre_results = lin_estimator_mult_treat_formula(combined_data, 
                                                  outcome_var, 
                                                  # we include `not_best_personalized_treatment_indicator` so that the 
                                                  # `best_personalized_treatment_indicator` is compared to control only
                                                  ['best_treatment_indicator', 
                                                   'not_best_treatment_indicator'], 
                                                  covariates_pre)[0]





best_treatments





# Shuffle data and split into folds
shuffled = combined_data.sample(frac=1, random_state=set_seed).copy()
folds = np.array_split(shuffled, num_folds)

features = covariates

# Initialize storage for results and effects
combined_data = data.iloc[:0,:].copy()
all_effects = []
best_treatments = []

# Iterate over each fold, using it as the test set, and the others as the training set
for i in range(num_folds):
    test_fold = folds[i]
    training_folds = pd.concat([folds[j] for j in range(num_folds) if j != i])
    
    # Train model on the combined training folds, predict on test data
    test_results = train_and_predict(training_folds, test_fold, features, set_seed)
    assign_best_personalized_treatment_indicator(test_fold, test_results)
    for fold_number in range(0, num_folds):
        test_fold[f'fold_{fold_number}'] = 0
    test_fold[f'fold_{i}'] = 1

    combined_data = pd.concat([combined_data, test_fold])

# Simple difference in means estimator
treatments_formula = " + ".join(['best_personalized_treatment_indicator', 
                                                   'not_best_personalized_treatment_indicator'])
formula = f"post_test ~ {treatments_formula}"

# Fit the regression model and save results object
model = sm.OLS.from_formula(formula, data=combined_data).fit()

model4_results = model.get_robustcov_results(cov_type="HC3")

model4_pre_results = lin_estimator_mult_treat_formula(combined_data, 
                                                  outcome_var, 
                                                  # we include `not_best_personalized_treatment_indicator` so that the 
                                                  # `best_personalized_treatment_indicator` is compared to control only
                                                  ['best_personalized_treatment_indicator', 
                                                   'not_best_personalized_treatment_indicator'], 
                                                  covariates_pre)[0]


print (summary_col([model3_pre_results, model4_pre_results],stars=True,float_format='%0.3f',
                  model_names=['Best fixed arm\n(1)', 'Best personalized arm\n(2)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept', 'best_treatment_indicator', 'best_personalized_treatment_indicator'],
                  drop_omitted=True))


# check that approximately 1/6 of people were assigned the best treatment and best personalized treatment
combined_data['best_treatment_indicator'].mean()


combined_data['best_personalized_treatment_indicator'].mean()


1/6





cd1 = combined_data.loc[combined_data['best_personalized_treatment'] == 'treatment_1']
cd2 = combined_data.loc[combined_data['best_personalized_treatment'] == 'treatment_2']
cd3 = combined_data.loc[combined_data['best_personalized_treatment'] == 'treatment_3']
cd4 = combined_data.loc[combined_data['best_personalized_treatment'] == 'treatment_4']
cd5 = combined_data.loc[combined_data['best_personalized_treatment'] == 'treatment_5']


model1_pre_results_1 = lin_estimator_mult_treat_formula(cd1,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]
model1_pre_results_2 = lin_estimator_mult_treat_formula(cd2,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]
model1_pre_results_3 = lin_estimator_mult_treat_formula(cd3,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]
model1_pre_results_4 = lin_estimator_mult_treat_formula(cd4,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]
model1_pre_results_5 = lin_estimator_mult_treat_formula(cd5,
                                                          "post_test",
                                                          treatment_vars,
                                                          covariates_pre)[0]


print (summary_col([model1_pre_results_1,
                   model1_pre_results_2,
                   model1_pre_results_3,
                   model1_pre_results_4,
                   model1_pre_results_5],stars=True,float_format='%0.3f',
                  model_names=['Lin (pre-test only)\nBest==1\n(1)',
                               'Lin (pre-test only)\nBest==2\n(2)',
                               'Lin (pre-test only)\nBest==3\n(3)',
                               'Lin (pre-test only)\nBest==4\n(4)',
                               'Lin (pre-test only)\nBest==5\n(5)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept'] + [f"treatment_{i}" for i in range(1, 6)],
                  drop_omitted=True))


cd1[covariates].describe().loc[['mean', 'std']]


cd2[covariates].describe().loc[['mean', 'std']]


cd3[covariates].describe().loc[['mean', 'std']]


cd4[covariates].describe().loc[['mean', 'std']]


cd5[covariates].describe().loc[['mean', 'std']]


print (summary_col([model3_pre_results, model4_pre_results],stars=True,float_format='%0.3f',
                  model_names=['Best fixed arm\n(1)', 'Best personalized arm\n(2)'],
                  info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
                             'R2':lambda x: "{:.2f}".format(x.rsquared)},
                  regressor_order=['Intercept', 'best_treatment_indicator', 'best_personalized_treatment_indicator', 
                                  'not_best_treatment_indicator', 'not_best_personalized_treatment_indicator'],
                  drop_omitted=True))






